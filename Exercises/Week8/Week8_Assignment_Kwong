BIO594 - Assignment Week 8
Kevin Wong
20180404

## Simulated Data
[kwong@KITT ~]$ cd repos/BIO_594_2018/Exercises/Week8/
[kwong@KITT Week8]$ ls
Exercise.md  kwong
[kwong@KITT Week8]$ cd kwong
[kwong@KITT kwong]$ ln -s /home/BIO594/Exercises/Week_7and8/simulated/*.fq.gz .
[kwong@KITT kwong]$ dDocent
dDocent 2.2.25

Contact jpuritz@gmail.com with any problems


Checking for required software
vcftools: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by vcftools)
/usr/local/bin/dDocent: line 83: [: : integer expression expected
/usr/local/bin/dDocent: line 89: [: : integer expression expected

All required software is installed!

dDocent run started Tue Apr 3 22:42:25 EDT 2018

80 individuals are detected. Is this correct? Enter yes or no and press [ENTER]

Incorrect Input
[kwong@KITT kwong]$ dDocent
dDocent 2.2.25

Contact jpuritz@gmail.com with any problems


Checking for required software
vcftools: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by vcftools)
/usr/local/bin/dDocent: line 83: [: : integer expression expected
/usr/local/bin/dDocent: line 89: [: : integer expression expected

All required software is installed!

dDocent run started Tue Apr 3 22:42:41 EDT 2018

80 individuals are detected. Is this correct? Enter yes or no and press [ENTER]
yes
Proceeding with 80 individuals
dDocent detects 80 processors available on this system.
Please enter the maximum number of processors to use for this analysis.
80
dDocent detects 503G maximum memory available on this system.
Please enter the maximum memory to use for this analysis. The size can be postfixed with
K, M, G, T, P, k, m, g, t, or p which would multiply the size with 1024, 1048576, 1073741824,
1099511627776, 1125899906842624, 1000, 1000000, 1000000000, 1000000000000, or 1000000000000000 respectively.
For example, to limit dDocent to ten gigabytes, enter 10G or 10g
0

Do you want to quality trim your reads?
Type yes or no and press [ENTER]?
yes

Do you want to perform an assembly?
Type yes or no and press [ENTER].
yes
What type of assembly would you like to perform?  Enter SE for single end, PE for paired-end, RPE for paired-end sequencing for RAD protocols with random shearing, or OL for paired-end sequencing that has substantial overlap.
Then press [ENTER]
PE
Reads will be assembled with Rainbow
CD-HIT will cluster reference sequences by similarity. The -c parameter (% similarity to cluster) may need to be changed for your taxa.
Would you like to enter a new c parameter now? Type yes or no and press [ENTER]
0.9
Incorrect input. Proceeding with the default value.
Do you want to map reads?  Type yes or no and press [ENTER]
yes
BWA will be used to map reads.  You may need to adjust -A -B and -O parameters for your taxa.
Would you like to enter a new parameters now? Type yes or no and press [ENTER]
1
Proceeding with default values for BWA read mapping.
Do you want to use FreeBayes to call SNPs?  Please type yes or no and press [ENTER]
4
Incorrect input
Do you want to use FreeBayes to call SNPs?  Please type yes or no and press [ENTER]
yes

Please enter your email address.  dDocent will email you when it is finished running.
Don't worry; dDocent has no financial need to sell your email address to spammers.
kevinhwong1@gmail.com


dDocent will require input during the assembly stage.  Please wait until prompt says it is safe to move program to the background.
Trimming reads and simultaneously assembling reference sequences


                      Number of Unique Sequences with More than X Coverage (Counted within individuals)

  105000 ++----------+-----------+-----------+-----------+----------+-----------+-----------+-----------+----------++
         +           +           +           +           +          +           +           +           +           +
         *****                                                                                                      |
  100000 ++   *                                                                                                    ++
         |     ******                                                                                               |
         |           ******                                                                                         |
         |                 ******                                                                                   |
   95000 ++                      ************                                                                      ++
         |                                   ******                                                                 |
         |                                         ******                                                           |
   90000 ++                                              ******                                                    ++
         |                                                     *****                                                |
         |                                                          ******                                          |
   85000 ++                                                               ******                                   ++
         |                                                                      ******                              |
         |                                                                            ******                        |
   80000 ++                                                                                 ******                 ++
         |                                                                                        ******            |
         |                                                                                              ******      |
         |                                                                                                    ******|
   75000 ++                                                                                                        +*
         |                                                                                                          |
         +           +           +           +           +          +           +           +           +           +
   70000 ++----------+-----------+-----------+-----------+----------+-----------+-----------+-----------+----------++
         2           4           6           8           10         12          14          16          18          20
                                                          Coverage

Please choose data cutoff.  In essence, you are picking a minimum (within individual) coverage level for a read (allele) to be used in the reference assembly
5


                               Number of Unique Sequences present in more than X Individuals

  3500 ++------------+------------+-------------+-------------+------------+-------------+------------+------------++
       +             +            +             +             +            +             +            +             +
       |                                                                                                            |
       |                                                                                                            |
       |    *                                                                                                       |
  3000 ++    *                                                                                                     ++
       |      *                                                                                                     |
       |       *                                                                                                    |
       |        *                                                                                                   |
  2500 ++        *                                                                                                 ++
       |          ***                                                                                               |
       |             *                                                                                              |
       |              *                                                                                             |
       |               ***                                                                                          |
  2000 ++                 ******                                                                                   ++
       |                        **                                                                                  |
       |                          ******                                                                            |
       |                                ********                                                                    |
  1500 ++                                       ********                                                           ++
       |                                                **************                                              |
       |                                                              *************                                 |
       |                                                                           *******************              |
       +             +            +             +             +            +             +            ***************
  1000 ++------------+------------+-------------+-------------+------------+-------------+------------+------------++
       0             5            10            15            20           25            30           35            40
                                                   Number of Individuals

Please choose data cutoff.  Pick point right before the assymptote. A good starting cutoff might be 10% of the total number of individuals
3
At this point, all configuration information has been entered and dDocent may take several hours to run.
It is recommended that you move this script to a background operation and disable terminal input and output.
All data and logfiles will still be recorded.
To do this:
Press control and Z simultaneously
Type 'bg' without the quotes and press enter
Type 'disown -h' again without the quotes and press enter

Now sit back, relax, and wait for your analysis to finish.
TrimmomaticSE: Started with arguments: -threads 80 -phred33 uniq.fq uniq.fq1 ILLUMINACLIP:/usr/local/bin/TruSeq2-PE.fa:2:30:10 MINLEN:153
Using PrefixPair: 'AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'CAAGCAGAAGACGGCATACGAGATCGGTCTCGGCATTCCTGCTGAACCGCTCTTCCGATCT'
Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATT'
Using Long Clipping Sequence: 'AGATCGGAAGAGCGGTTCAGCAGGAATGCCGAGACCGATCTCGTATGCCGTCTTCTGCTTG'
Using Long Clipping Sequence: 'TTTTTTTTTTAATGATACGGCGACCACCGAGATCTACAC'
Using Long Clipping Sequence: 'TTTTTTTTTTCAAGCAGAAGACGGCATACGA'
Using Long Clipping Sequence: 'CAAGCAGAAGACGGCATACGAGATCGGTCTCGGCATTCCTGCTGAACCGCTCTTCCGATCT'
Using Long Clipping Sequence: 'AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT'
ILLUMINACLIP: Using 1 prefix pairs, 6 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences
Input Reads: 2691 Surviving: 2691 (100.00%) Dropped: 0 (0.00%)
TrimmomaticSE: Completed successfully
 ____  _____    _    ____
|  _ \| ____|  / \  |  _ \
| |_) |  _|   / _ \ | |_) |
|  __/| |___ / ___ \|  _ <
|_|   |_____/_/   \_\_| \_\

PEAR v0.9.11 [Nov 5, 2017]

Citation - PEAR: a fast and accurate Illumina Paired-End reAd mergeR
Zhang et al (2014) Bioinformatics 30(5): 614-620 | doi:10.1093/bioinformatics/btt593

Forward reads file.................: ref.F.fq
Reverse reads file.................: ref.R.fq
PHRED..............................: 33
Using empirical frequencies........: YES
Statistical method.................: OES
Maximum assembly length............: 999999
Minimum assembly length............: 255
p-value............................: 0.001000
Quality score threshold (trimming).: 0
Minimum read size after trimming...: 1
Maximal ratio of uncalled bases....: 1.000000
Minimum overlap....................: 10
Scoring method.....................: Scaled score
Threads............................: 80

Allocating memory..................: 200,000,000 bytes
Computing empirical frequencies....: DONE
  A: 0.254650
  C: 0.245794
  G: 0.245856
  T: 0.253699
  0 uncalled bases
Assemblying reads: 100%

Assembled reads ...................: 0 / 1,000 (0.000%)
Discarded reads ...................: 0 / 1,000 (0.000%)
Not assembled reads ...............: 1,000 / 1,000 (100.000%)
Assembled reads file...............: overlap.assembled.fastq
Discarded reads file...............: overlap.discarded.fastq
Unassembled forward reads file.....: overlap.unassembled.forward.fastq
Unassembled reverse reads file.....: overlap.unassembled.reverse.fastq
================================================================
Program: CD-HIT, V4.6 (+OpenMP), Jan 11 2018, 15:28:37
Command: cd-hit-est -i totalover.fasta -o
         reference.fasta.original -M 0 -T 0 -c 0.9

Started: Tue Apr  3 22:47:02 2018
================================================================
                            Output
----------------------------------------------------------------
total number of CPUs in the system is 80
Actual number of CPUs to be used: 80

total seq: 1000
longest and shortest : 222 and 204
Total letters: 204443
Sequences have been sorted

Approximated minimal memory consumption:
Sequence        : 0M
Buffer          : 80 X 12M = 968M
Table           : 2 X 16M = 33M
Miscellaneous   : 4M
Total           : 1006M

Table limit with the given memory limit:
Max number of representatives: 248606
Max number of word counting entries: 9453957

# comparing sequences from          0  to       1000
.---------- new table with     1000 representatives

     1000  finished       1000  clusters

Apprixmated maximum memory consumption: 1007M
writing new database
writing clustering information
program completed !

Total CPU time 1.61
[bwa_index] Pack FASTA... 0.00 sec
[bwa_index] Construct BWT for the packed sequence...
[bwa_index] 0.04 seconds elapse.
[bwa_index] Update BWT... 0.00 sec
[bwa_index] Pack forward-only FASTA... 0.01 sec
[bwa_index] Construct SA from BWT and Occ... 0.03 sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa index reference.fasta
[main] Real time: 0.098 sec; CPU: 0.087 sec
Using BWA to map reads.
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
[bam_sort_core] merging from 0 files and 80 in-memory blocks...
Creating alignment intervals
Using FreeBayes to call SNPs
Using VCFtools to parse TotalRawSNPS.vcf for SNPs that are called in at least 90% of individuals
[kwong@KITT kwong]$ source activate /home/BIO594/Exercises/Week_7and8/simulated/environ

CondaValueError: Could not find environment: /home/BIO594/Exercises/Week_7and8/simulated/environ

[kwong@KITT kwong]$ mkdir Filter
[kwong@KITT kwong]$ cd Filter/
[kwong@KITT Filter]$ ln -s ../TotalRawSNPs.vcf .
[kwong@KITT Filter]$ vcftools --vcf TotalRawSNPs.vcf --max-missing 0.5 --maf 0.001 --minQ 20 --recode --recode-INFO-all --out TRS
vcftools: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by vcftools)
[kwong@KITT Filter]$ conda create -n week8 ddocent
Fetching package metadata .................
Solving package specifications: .

Package plan for installation in environment /home/kwong/miniconda3/envs/week8:

The following NEW packages will be INSTALLED:

    bamtools:          2.4.1-1                bioconda
    bedtools:          2.26.0-0               bioconda
    bwa:               0.7.17-pl5.22.0_2      bioconda
    bzip2:             1.0.6-1                conda-forge
    ca-certificates:   2018.1.18-0            conda-forge
    cd-hit:            4.6.8-0                bioconda
    cmake:             3.11.0-0               conda-forge
    curl:              7.59.0-0               conda-forge
    ddocent:           2.2.25-bamtools2.4.1_2 bioconda
    expat:             2.2.5-0                conda-forge
    fontconfig:        2.12.6-0               conda-forge
    freebayes:         1.0.2-0                bioconda
    freetype:          2.8.1-0                conda-forge
    gawk:              4.1.3-1                bioconda
    giflib:            5.1.4-0                conda-forge
    gmp:               6.1.2-0                conda-forge
    gnuplot:           5.0.4-ncurses5.9_1     bioconda
    grep:              2.14-1                 bioconda
    icu:               58.2-0                 conda-forge
    jpeg:              9b-2                   conda-forge
    krb5:              1.14.6-0               conda-forge
    libgcc:            7.2.0-h69d50b8_2
    libgcc-ng:         7.2.0-hdf63c60_3
    libgd:             2.2.5-3                conda-forge
    libiconv:          1.15-0                 conda-forge
    libpng:            1.6.34-0               conda-forge
    libssh2:           1.8.0-2                conda-forge
    libstdcxx-ng:      7.2.0-hdf63c60_3
    libtiff:           4.0.9-0                conda-forge
    libuv:             1.19.2-0               conda-forge
    libwebp:           0.5.2-7                conda-forge
    libxml2:           2.9.8-0                conda-forge
    llvm-meta:         6.0.0-0                conda-forge
    mawk:              1.3.4-0                bioconda
    mpfr:              3.1.5-0                conda-forge
    ncurses:           5.9-10                 conda-forge
    openjdk:           8.0.121-1
    openmp:            6.0.0-0                conda-forge
    openssl:           1.0.2n-0               conda-forge
    parallel:          20170422-pl5.22.0_0    bioconda
    pear:              0.9.6-3                bioconda
    perl:              5.22.0.1-0             conda-forge
    perl-threaded:     5.22.0-pl5.22.0_12     bioconda
    perl-vcftools-vcf: 0.953-3                bioconda
    rainbow:           2.0.4-0                bioconda
    readline:          7.0-0                  conda-forge
    rhash:             1.3.4-0                conda-forge
    samtools:          1.8-2                  bioconda
    seqtk:             1.2-1                  bioconda
    stacks:            2.0Beta8-pl5.22.0_1    bioconda
    trimmomatic:       0.36-5                 bioconda
    unzip:             6.0-0                  conda-forge
    vcflib:            1.0.0_rc1-1            bioconda
    vcftools:          0.1.14-5               bioconda
    velvet:            1.2.10-1               bioconda
    xz:                5.2.3-0                conda-forge
    zlib:              1.2.11-0               conda-forge

Proceed ([y]/n)? y

krb5-1.14.6-0. 100% |############################################################################################| Time: 0:00:00   8.50 MB/s
libgcc-ng-7.2. 100% |############################################################################################| Time: 0:00:00  10.32 MB/s
libstdcxx-ng-7 100% |############################################################################################| Time: 0:00:00  11.85 MB/s
llvm-meta-6.0. 100% |############################################################################################| Time: 0:00:00   3.14 MB/s
libxml2-2.9.8- 100% |############################################################################################| Time: 0:00:00   8.68 MB/s
openmp-6.0.0-0 100% |############################################################################################| Time: 0:00:00   7.35 MB/s
curl-7.59.0-0. 100% |############################################################################################| Time: 0:00:00   6.05 MB/s
cmake-3.11.0-0 100% |############################################################################################| Time: 0:00:01   8.25 MB/s
samtools-1.8-2 100% |############################################################################################| Time: 0:00:00  10.43 MB/s
#
# To activate this environment, use:
# > source activate week8
#
# To deactivate an active environment, use:
# > source deactivate
#

[kwong@KITT Filter]$ source activate week8
(week8) [kwong@KITT Filter]$ vcftools --vcf TotalRawSNPs.vcf --max-missing 0.5 --maf 0.001 --minQ 20 --recode --recode-INFO-all --out TRS

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TotalRawSNPs.vcf
	--recode-INFO-all
	--maf 0.001
	--minQ 20
	--max-missing 0.5
	--out TRS
	--recode

After filtering, kept 80 out of 80 Individuals
Outputting VCF file...
After filtering, kept 2955 out of a possible 2987 Sites
Run Time = 2.00 seconds
(week8) [kwong@KITT Filter]$ vcftools --vcf TRS.recode.vcf --minDP 5 --recode --recode-INFO-all --out TRSdp5

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRS.recode.vcf
	--recode-INFO-all
	--minDP 5
	--out TRSdp5
	--recode

After filtering, kept 80 out of 80 Individuals
Outputting VCF file...
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 2.00 seconds
(week8) [kwong@KITT Filter]$ pop_missing_filter.sh TRSdp5.recode.vcf ../popmap 0.05 1 TRSdp5p05
rm: cannot remove ‘badloci’: No such file or directory

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopA
	--out PopA
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopB
	--out PopB
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopC
	--out PopC
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopD
	--out PopD
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--exclude-positions loci.to.remove
	--recode-INFO-all
	--out TRSdp5p05
	--recode

After filtering, kept 80 out of 80 Individuals
Outputting VCF file...
After filtering, kept 2775 out of a possible 2955 Sites
Run Time = 1.00 seconds
(week8) [kwong@KITT Filter]$ pop_missing_filter.sh TRSdp5.recode.vcf /home/BIO594/Exercises/Week_7and8/simulated/popmap 0.05 1 TRSdp5p05

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopA
	--out PopA
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopB
	--out PopB
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopC
	--out PopC
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--keep keep.PopD
	--out PopD
	--missing-site

Keeping individuals in 'keep' list
After filtering, kept 20 out of 80 Individuals
Outputting Site Missingness
After filtering, kept 2955 out of a possible 2955 Sites
Run Time = 0.00 seconds

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5.recode.vcf
	--exclude-positions loci.to.remove
	--recode-INFO-all
	--out TRSdp5p05
	--recode

After filtering, kept 80 out of 80 Individuals
Outputting VCF file...
After filtering, kept 2775 out of a possible 2955 Sites
Run Time = 2.00 seconds
(week8) [kwong@KITT Filter]$ dDocent_filters TRSdp5p05.recode.vcf TRSdp5p05
This script will automatically filter a FreeBayes generated VCF file using criteria related to site depth,
quality versus depth, strand representation, allelic balance at heterzygous individuals, and paired read representation.
The script assumes that loci and individuals with low call rates (or depth) have already been removed.

Contact Jon Puritz (jpuritz@gmail.com) for questions and see script comments for more details on particular filters

Number of sites filtered based on allele balance at heterozygous loci, locus quality, and mapping quality / Depth
 673 of 2775

Number of additional sites filtered based on overlapping forward and reverse reads
 0 of 2102

Is this from a mixture of SE and PE libraries? Enter yes or no.
no
Number of additional sites filtered based on properly paired status
 0 of 2102

Number of sites filtered based on high depth and lower than 2*DEPTH quality score
 278 of 2102



                                             Histogram of mean depth per site

  250 +-+-+---+---+---+---+---+---+--+---+---+---+---+---+---+---+---+---+---+---+---+---+--+---+---+---+---+---+-+-+
      +   +   +   +   +   +   +   +  +   +   +   +   +   +   +   +   +   +   +   +   +   +  +   +   +   +   +   +   +
      |                                      *            'meandepthpersite' using (bin($1,binwidth)):(1.0) ******* |
      |                                      *                                                                      |
      |                                     ***                                                                     |
  200 +-+                                  ****                                                                   +-+
      |                                    ****                                                                     |
      |                                   *****                                                                     |
      |                                   *****                                                                     |
  150 +-+                                ******                                                                   +-+
      |                                  *******                                                                    |
      |                                  *******                                                                    |
      |                                  ********                                                                   |
      |                                  ********                                                                   |
  100 +-+                                ********                                                                 +-+
      |                                  ********                                                                   |
      |                                  ********                                                                   |
      |                                **********                                                                   |
   50 +-+                              **********                                                                 +-+
      |                               ***********                                                                   |
      |                              ***************                                                                |
      |                              ***************                                                                |
      +   +   +   +   +   +   +   +  ****************+   +   +   +   +   +   +   +   +   +  +   +   +   +   +   +   +
    0 +-+-+---+---+---+---+---+---+********************--+---+---+---+---+---+---+---+---+--+---+---+---+---+---+-+-+
      10  15  20  25  30  35  40  45 50  55  60  65  70  75  80  85  90  95 100 105 110 11 120 125 130 135 140 145 150
                                                        Mean Depth

If distrubtion looks normal, a 1.645 sigma cutoff (~90% of the data) would be 5169.721675
The 95% cutoff would be 64
Would you like to use a different maximum mean depth cutoff than 64, yes or no
yes
Please enter new cutoff
75
Number of sites filtered based on maximum mean depth
 0 of 2102

Number of sites filtered based on within locus depth mismatch
 0 of 1938

Total number of sites filtered
 837 of 2775

Remaining sites
 1938

Filtered VCF file is called Output_prefix.FIL.recode.vcf

Filter stats stored in TRSdp5p05.filterstats
(week8) [kwong@KITT Filter]$ vcfallelicprimitives -k -g TRSdp5p05.FIL.recode.vcf |sed 's:\.|\.:\.\/\.:g' > TRSdp5p05F.prim
(week8) [kwong@KITT Filter]$ vcftools --vcf TRSdp5p05F.prim --recode --recode-INFO-all --remove-indels --out SNP.TRSdp5p05F

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf TRSdp5p05F.prim
	--recode-INFO-all
	--out SNP.TRSdp5p05F
	--recode
	--remove-indels

After filtering, kept 80 out of 80 Individuals
Outputting VCF file...
After filtering, kept 1711 out of a possible 2107 Sites
Run Time = 1.00 seconds
(week8) [kwong@KITT Filter]$ filter_hwe_by_pop.pl -v SNP.TRSdp5p05F.recode.vcf -p /home/BIO594/Exercises/Week_7and8/simulated/popmap -c 0.5 -out SNP.TRSdp5p05FHWE
Processing population: PopA (20 inds)
Processing population: PopB (20 inds)
Processing population: PopC (20 inds)
Processing population: PopD (20 inds)
Outputting results of HWE test for filtered loci to 'filtered.hwe'
Kept 1711 of a possible 1711 loci (filtered 0 loci)
(week8) [kwong@KITT Filter]$ vcftools --vcf SNP.TRSdp5p05FHWE.recode.vcf --maf 0.05 --recode --recode-INFO-all --out SNP.TRSdp5p05FHWEmaf05

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf SNP.TRSdp5p05FHWE.recode.vcf
	--recode-INFO-all
	--maf 0.05
	--out SNP.TRSdp5p05FHWEmaf05
	--recode

After filtering, kept 80 out of 80 Individuals
Outputting VCF file...
After filtering, kept 933 out of a possible 1711 Sites
Run Time = 0.00 seconds
(week8) [kwong@KITT Filter]$ cp /home/BIO594/Exercises/Week_7and8/simulated/BSsnp.spid .
(week8) [kwong@KITT Filter]$ ln -s cp /home/BIO594/Exercises//Week_7and8/simulated/popmap .
(week8) [kwong@KITT Filter]$ ava -jar /usr/local/bin/PGDSpider2-cli.jar -inputfile SNP.TRSdp5p05FHWEmaf05.recode.vcf -outputfile SNP.TRSdp5p05FHWEBS -spid BSsnp.spid
bash: ava: command not found...
(week8) [kwong@KITT Filter]$ java -jar /usr/local/bin/PGDSpider2-cli.jar -inputfile SNP.TRSdp5p05FHWEmaf05.recode.vcf -outputfile SNP.TRSdp5p05FHWEBS -spid BSsnp.spid
WARN  23:22:53 - PGDSpider configuration file not found! Loading default configuration.
initialize convert process...
read input file...
read input file done.
write output file...
write output file done.
(week8) [kwong@KITT Filter]$ BayeScan2.1_linux64bits SNP.TRSdp5p05FHWEBS -nbp 30 -thin 20
Using 80 threads (80 cpu detected on this machine)
Pilot runs...
1% 2% 3% 4% 5% 6% 7% 8% 9% 10% 11% 12% 13% 14% 15% 16% 17% 18% 19% 20% 21% 22% 23% 24% 25% 26% 27% 28% 29% 30% 31% 32% 33% 34% 35% 36% 37% 38% 39% 40% 41% 42% 43% 44% 45% 46% 47% 48% 49% 50% 51% 52% 53% 54% 55% 56% 57% 58% 59% 60% 61% 62% 63% 64% 65% 66% 67% 68% 69% 70% 71% 72% 73% 74% 75% 76% 77% 78% 79% 80% 81% 82% 83% 84% 85% 86% 87% 88% 89% 90% 91% 92% 93% 94% 95% 96% 97% 98% 99%
Calculation...
1% 2% 3% 4% 5% 6% 7% 8% 9% 10% 11% 12% 13% 14% 15% 16% 17% 18% 19% 20% 21% 22% 23% 24% 25% 26% 27% 28% 29% 30% 31% 32% 33% 34% 35% 36% 37% 38% 39% 40% 41% 42% 43% 44% 45% 46% 47% 48% 49% 50% 51% 52% 53% 54% 55% 56% 57% 58% 59% 60% 61% 62% 63% 64% 65% 66% 67% 68% 69% 70% 71% 72% 73% 74% 75% 76% 77% 78% 79% 80% 81% 82% 83% 84% 85% 86% 87% 88% 89% 90% 91% 92% 93% 94% 95% 96% 97% 98% 99%
(week8) [kwong@KITT Filter]$ cp /home/BIO594/Exercises/Week_7and8/simulated/plot_R.r .
(week8) [kwong@KITT Filter]$ R

R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> source("plot_R.r")
> plot_bayescan("SNP.TRSdp5p05FH_fst.txt")
$outliers
[1] 217 340 341 519 520

$nb_outliers
[1] 5

> quit
function (save = "default", status = 0, runLast = TRUE)
.Internal(quit(save, status, runLast))
<bytecode: 0x46ffba0>
<environment: namespace:base>
> save
function (..., list = character(), file = stop("'file' must be specified"),
    ascii = FALSE, version = NULL, envir = parent.frame(), compress = isTRUE(!ascii),
    compression_level, eval.promises = TRUE, precheck = TRUE)
{
    opts <- getOption("save.defaults")
    if (missing(compress) && !is.null(opts$compress))
        compress <- opts$compress
    if (missing(compression_level) && !is.null(opts$compression_level))
        compression_level <- opts$compression_level
    if (missing(ascii) && !is.null(opts$ascii))
        ascii <- opts$ascii
    if (missing(version))
        version <- opts$version
    if (!is.null(version) && version < 2)
        warning("Use of save versions prior to 2 is deprecated",
            domain = NA)
    names <- as.character(substitute(list(...)))[-1L]
    if (missing(list) && !length(names))
        warning("nothing specified to be save()d")
    list <- c(list, names)
    if (!is.null(version) && version == 1)
        .Internal(save(list, file, ascii, version, envir, eval.promises))
    else {
        if (precheck) {
            ok <- vapply(list, exists, NA, envir = envir)
            if (!all(ok)) {
                n <- sum(!ok)
                stop(sprintf(ngettext(n, "object %s not found",
                  "objects %s not found"), paste(sQuote(list[!ok]),
                  collapse = ", ")), domain = NA)
            }
        }
        if (is.character(file)) {
            if (!nzchar(file))
                stop("'file' must be non-empty string")
            if (!is.character(compress)) {
                if (!is.logical(compress))
                  stop("'compress' must be logical or character")
                compress <- if (compress)
                  "gzip"
                else "no compression"
            }
            con <- switch(compress, bzip2 = {
                if (!missing(compression_level)) bzfile(file,
                  "wb", compression = compression_level) else bzfile(file,
                  "wb")
            }, xz = {
                if (!missing(compression_level)) xzfile(file,
                  "wb", compression = compression_level) else xzfile(file,
                  "wb", compression = 9)
            }, gzip = {
                if (!missing(compression_level)) gzfile(file,
                  "wb", compression = compression_level) else gzfile(file,
                  "wb")
            }, `no compression` = file(file, "wb"), stop(gettextf("'compress = \"%s\"' is invalid",
                compress)))
            on.exit(close(con))
        }
        else if (inherits(file, "connection"))
            con <- file
        else stop("bad file argument")
        if (isOpen(con) && !ascii && summary(con)$text != "binary")
            stop("can only save to a binary connection")
        .Internal(saveToConn(list, con, ascii, version, envir,
            eval.promises))
    }
}
<bytecode: 0x47023c8>
<environment: namespace:base>
>
> exit
Error: object 'exit' not found
> quit
function (save = "default", status = 0, runLast = TRUE)
.Internal(quit(save, status, runLast))
<bytecode: 0x46ffba0>
<environment: namespace:base>
> quit()
Save workspace image? [y/n/c]: y
(week8) [kwong@KITT Filter]$ vcftools --vcf SNP.TRSdp5p05FHWEmaf05.recode.vcf --max-alleles 2 --recode --recode-INFO-all --out SNP.TRSdp5p05FHWE2A

VCFtools - 0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf SNP.TRSdp5p05FHWEmaf05.recode.vcf
	--recode-INFO-all
	--max-alleles 2
	--out SNP.TRSdp5p05FHWE2A
	--recode

After filtering, kept 80 out of 80 Individuals
Outputting VCF file...
After filtering, kept 930 out of a possible 933 Sites
Run Time = 1.00 seconds
(week8) [kwong@KITT Filter]$ R

R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(pcadapt)
> filename <- read.pcadapt("SNP.TRSdp5p05FHWE2A.recode.vcf", type = "vcf" )
No variant got discarded.
Summary:

	- input file:				SNP.TRSdp5p05FHWE2A.recode.vcf
	- output file:				SNP.TRSdp5p05FHWE2A.recode.pcadapt

	- number of individuals detected:	80
	- number of loci detected:		930

> x <- pcadapt(input = filename, K = 20)
Reading file /home/kwong/repos/BIO_594_2018/Exercises/Week8/kwong/Filter/SNP.TRSdp5p05FHWE2A.recode.pcadapt...
Number of SNPs: 930
Number of individuals: 80
> plot(x, option = "screeplot")
> plot(x, option = "screeplot", K = 10)
> poplist.names <- c(rep("POPA", 20),rep("POPB", 20),rep("POPC", 20), rep("POPD",20))
> plot(x, option = "scores", pop = poplist.names)
> plot(x, option = "scores", i = 2, j = 3, pop = poplist.names)
> plot(x, option = "scores", i = 3, j = 4, pop = poplist.names)
> x <- pcadapt(filename, K = 3)
Reading file /home/kwong/repos/BIO_594_2018/Exercises/Week8/kwong/Filter/SNP.TRSdp5p05FHWE2A.recode.pcadapt...
Number of SNPs: 930
Number of individuals: 80
> summary(x)
                Length Class  Mode
scores           240   -none- numeric
singular.values    3   -none- numeric
zscores         2790   -none- numeric
loadings        2790   -none- numeric
maf              930   -none- numeric
missing          930   -none- numeric
stat             930   -none- numeric
gif                1   -none- numeric
chi2.stat        930   -none- numeric
pvalues          930   -none- numeric
> plot(x , option = "manhattan")
> plot(x, option = "qqplot", threshold = 0.1)
> plot(x, option = "stat.distribution")
Warning message:
In grid.Call.graphics(C_rect, x$x, x$y, x$width, x$height, resolveHJust(x$just,  :
  semi-transparency is not supported on this device: reported only once per page
> library(qvalue)
> qval <- qvalue(x$pvalues)$qvalues
> alpha <- 0.1
> outliers <- which(qval < alpha)
> poplist.names <- c(rep("LIB1", 40),rep("LIB2", 40))
> x <- pcadapt(input = filename, K = 20)
Reading file /home/kwong/repos/BIO_594_2018/Exercises/Week8/kwong/Filter/SNP.TRSdp5p05FHWE2A.recode.pcadapt...
Number of SNPs: 930
Number of individuals: 80
>
> plot(x, option = "scores", pop = poplist.names)
> plot(x, option = "scores", i = 2, j = 3, pop = poplist.names)
> x <- pcadapt(filename, K = 2)
Reading file /home/kwong/repos/BIO_594_2018/Exercises/Week8/kwong/Filter/SNP.TRSdp5p05FHWE2A.recode.pcadapt...
Number of SNPs: 930
Number of individuals: 80
>
> summary(x)
                Length Class  Mode
scores           160   -none- numeric
singular.values    2   -none- numeric
zscores         1860   -none- numeric
loadings        1860   -none- numeric
maf              930   -none- numeric
missing          930   -none- numeric
stat             930   -none- numeric
gif                1   -none- numeric
chi2.stat        930   -none- numeric
pvalues          930   -none- numeric
> plot(x , option = "manhattan")
> plot(x, option = "qqplot", threshold = 0.1)
> plot(x, option = "stat.distribution")
Warning message:
In grid.Call.graphics(C_rect, x$x, x$y, x$width, x$height, resolveHJust(x$just,  :
  semi-transparency is not supported on this device: reported only once per page
> library(qvalue)
> qval <- qvalue(x$pvalues)$qvalues
> alpha <- 0.1
> outliers <- which(qval < alpha)
> quit()
Save workspace image? [y/n/c]: y

(week8) [kwong@KITT Filter]$ cp /home/BIO594/Exercises/Week_7and8/simulated/LibraryInfo .
(week8) [kwong@KITT Filter]$ R

R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]
> strata <- read.table("LibraryInfo", header=TRUE)
> strata_df <- data.frame(strata)
> strata(my_genind) <- strata_df
Error in strata(my_genind) <- strata_df :
  could not find function "strata<-"
> library(adegenet)
Loading required package: ade4

   /// adegenet 2.1.1 is loaded ////////////

   > overview: '?adegenet'
   > tutorials/doc/questions: 'adegenetWeb()'
   > bug reports/feature requests: adegenetIssues()


> library(vcfR)

   *****       ***   vcfR   ***       *****
   This is vcfR 1.7.0
     browseVignettes('vcfR') # Documentation
     citation('vcfR') # Citation
   *****       *****      *****       *****

>
> library(vcfR)
> my_vcf <- read.vcfR("SNP.TRSdp5p05FHWE2A.recode.vcf")
Scanning file to determine attributes.
File attributes:
  meta lines: 65
  header line: 66
  variant count: 930
  column count: 89
Meta line 65 read in.
All meta lines processed.
gt matrix initialized.
Character matrix gt created.
  Character matrix gt rows: 930
  Character matrix gt cols: 89
  skip: 0
  nrows: 930
  row_num: 0
  > my_genind <- vcfR2genind(my_vcf)
  > strata<- read.table("LibraryInfo", header=TRUE)
  > strata_df <- data.frame(strata)
  > strata(my_genind) <- strata_df
  > setPop(my_genind) <- ~Population
  > library("hierfstat")

  Attaching package: ‘hierfstat’

  The following object is masked from ‘package:adegenet’:

      read.fstat

  > fstat(my_genind)
               pop       Ind
  Total 0.08214408 0.2280255
  pop   0.00000000 0.1589372
  > matFst <- pairwise.fst(my_genind)

  > X <- tab(my_genind, freq = TRUE, NA.method = "mean")
  > pca1 <- dudi.pca(X, scale = FALSE, scannf = FALSE, nf = 3)
  > barplot(pca1$eig[1:50], main = "PCA eigenvalues", col = heat.colors(50))
  > s.class(pca1$li, pop(my_genind))
  > title("PCA of simulated dataset\naxes 1-2")
  > add.scatter.eig(pca1$eig[1:20], 3,1,2)
  >
  > col <- funky(15)
  > s.class(pca1$li, pop(my_genind),xax=1,yax=2, col=col, axesell=FALSE, cstar=0, cpoint=3, grid=FALSE)
  >
  > #DAPC
  > grp <- find.clusters(my_genind, max.n.clust=40)
  Choose the number PCs to retain (>= 1): 80
    [Bookmarked Apr 4, 2018, 10:40:15 AM]
  Choose the number of clusters (>=2: 2
  > table(pop(my_genind), grp$grp)

          1  2
    PopA 20  0
    PopB 20  0
    PopC 20  0
    PopD  0 20
  > table.value(table(pop(my_genind), grp$grp), col.lab=paste("inf", 1:2), row.lab=paste("ori", 1:4))
  > dapc1 <- dapc(my_genind, grp$grp)
  Choose the number PCs to retain (>=1): 40
  Choose the number discriminant functions to retain (>=1): 2
  > scatter(dapc1,col=col,bg="white", solid=1)
  > contrib <- loadingplot(dapc1$var.contr, axis=1, thres=.01, lab.jitter=1)
  > contrib
  NULL
  > setPop(my_genind) <- ~Library
  > dapc1 <- dapc(my_genind, pop(my_genind))
  Choose the number PCs to retain (>=1): 40
  Choose the number discriminant functions to retain (>=1): 2
  > contrib <- loadingplot(dapc1$var.contr, axis=1, thres=.05, lab.jitter=1)

## Read Data
[kwong@KITT kwong]$ cd Filter/
[kwong@KITT Filter]$ BayeScan2.1_linux64bits SNP.TRSdp5p05FHWEBS -nbp 30 -thin 20
Using 80 threads (80 cpu detected on this machine)
Pilot runs...
1% 2% 3% 4% 5% 6% 7% 8% 9% 10% 11% 12% 13% 14% 15% 16% 17% 18% 19% 20% 21% 22% 23% 24% 25% 26% 27% 28% 29% 30% 31% 32% 33% 34% 35% 36% 37% 38% 39% 40% 41% 42% 43% 44% 45% 46% 47% 48% 49% 50% 51% 52% 53% 54% 55% 56% 57% 58% 59% 60% 61% 62% 63% 64% 65% 66% 67% 68% 69% 70% 71% 72% 73% 74% 75% 76% 77% 78% 79% 80% 81% 82% 83% 84% 85% 86% 87% 88% 89% 90% 91% 92% 93% 94% 95% 96% 97% 98% 99%
Calculation...
1% 2% 3% 4% 5% 6% 7% 8% 9% 10% 11% 12% 13% 14% 15% 16% 17% 18% 19% 20% 21% 22% 23% 24% 25% 26% 27% 28% 29% 30% 31% 32% 33% 34% 35% 36% 37% 38% 39% 40% 41% 42% 43% 44% 45% 46% 47% 48% 49% 50% 51% 52% 53% 54% 55% 56% 57% 58% 59% 60% 61% 62% 63% 64% 65% 66% 67% 68% 69% 70% 71% 72% 73% 74% 75% 76% 77% 78% 79% 80% 81% 82% 83% 84% 85% 86% 87% 88% 89% 90% 91% 92% 93% 94% 95% 96% 97% 98% 99%

[kwong@KITT Filter]$ cp /home/BIO594/Exercises/Week_7and8/realdata/plot_R.r .
cp: overwrite ‘./plot_R.r’? yes
[kwong@KITT Filter]$ R

R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> source("plot_R.r")
> plot_bayescan("SNP.TRSdp5p05FHWEBS")
Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :
  line 1 did not have 5 elements
> plot_bayescan("SNP.TRSdp5p05FH_fst.txt")
$outliers
[1] 217 340 341 519 520

$nb_outliers
[1] 5

> 
